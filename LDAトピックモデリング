# 必要なライブラリのインポート
import fugashi
from gensim.corpora import Dictionary
from gensim.models import LdaModel
from bertopic import BERTopic
from transformers import BertModel, BertTokenizer
import torch

# 日本語の分かち書き用にfugashiを初期化
tagger = fugashi.Tagger()

# 日本語歌詞データ
lyrics = [
    "いつからか時間が止まっていた",
    "右に左に音の波の中",
    "これでいいかとうなづいたときに",
    "あいつ変だと指をさされたよ",
    "もう戻れない場所を思うときに",
    "もう会えない人を思うときに",
    "アンプ蹴ったらギャンギャン泣いた",
    "１５ワットの小さな世界が",
    "アンプを蹴りとばしたんだ",
    "ディストーション、壁を叩いた"
]

# 歌詞の分かち書き
tokenized_lyrics = [[word for word in tagger.parse(lyric).strip().split()] for lyric in lyrics]

# **LDAトピックモデリング**
# 辞書の作成とコーパスの生成
dictionary = Dictionary(tokenized_lyrics)
corpus = [dictionary.doc2bow(text) for text in tokenized_lyrics]

# LDAモデルの訓練
lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=2, random_state=42, passes=10)

# トピック表示
print("LDAトピック:")
for idx, topic in lda_model.print_topics():
    print(f"トピック {idx}: {topic}")

# **BERTopic**
# BERTモデルとトークナイザーの準備
tokenizer = BertTokenizer.from_pretrained("cl-tohoku/bert-base-japanese")
model = BertModel.from_pretrained("cl-tohoku/bert-base-japanese")

# 歌詞をBERTでベクトル化
embeddings = []
for lyric in lyrics:
    encoded_input = tokenizer(lyric, return_tensors="pt")
    output = model(**encoded_input)
    embeddings.append(output.last_hidden_state.mean(dim=1).squeeze().detach().numpy())

# BERTopicモデルの作成とトピック抽出
topic_model = BERTopic()
topics, probs = topic_model.fit_transform(lyrics, embeddings)

# トピック結果を表示
print("\nBERTopicトピック:")
for topic_num, topic_words in topic_model.get_topics().items():
    print(f"トピック {topic_num}: {topic_words}")
